[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Robin Penfold",
    "section": "",
    "text": "Projecting portfolio risk\n\n\n\n\n\nRisk analysis is a standard technique within quantitative investment. In this post, I’ll describe how to perform it succinctly in R.\n\n\n\n\n\nMay 20, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nWinning at Wordle\n\n\n\n\n\nWordle is a source of healthy competition in our family. So, with a long train journey ahead of me, I thought I would embrace my nerd power and gain a competitive edge over my wife! I downloaded the most common five-letter words from the internet and analysed them with the following code. This leads me to suggest — only in the context of Wordle — that you should STARE at the CHILD that is FUNKY. \n\n\n\n\n\nDec 30, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nPremPredict\n\n\n\n\n\nThey think it’s all over. It is now.\n\n\n\n\n\nSep 19, 2020\n\n\n\n\n\n\n\n\n\n\n\n\nAsset manager evaluation\n\n\n\n\n\nBack in the day, I wrote research papers about investment practice. One example concerned how asset owners could better evaluate the investment performance of their asset managers. Basically, the idea is to view performance in the way that a Bayesian would. \n\n\n\n\n\nOct 20, 2016\n\n\n\n\n\n\n\n\n\n\n\n\nBrexit vote analysis\n\n\n\n\n\nI wanted more insight into the recent vote and so investigated each constituency, comparing the Brexit vote with that of the winning parliamentary party from 2016 \n\n\n\n\n\nOct 12, 2016\n\n\n\n\n\n\n\n\n\n\n\n\nHave batting averages improved over time?\n\n\n\n\n\nCricket commentators often talk of changes in batting quality through the ages. But is there any truth to this? \n\n\n\n\n\nOct 9, 2016\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/evaluation/index.html",
    "href": "posts/evaluation/index.html",
    "title": "Asset manager evaluation",
    "section": "",
    "text": "The idea is pretty simple, which I’ll outline below. (I can do so, as the materials are already in the public domain.)\nIf you want the details, check out the formal paper at SSRN. For a more accessible introduction, I’d recommend the video below that was taken (and won an award) at the International Congress of Actuaries in 2014.\n\n\n\nThe gist of the idea\nIn short, a key mantra of investment advisors is that asset owners should ignore the performance of their asset manager. Whether the manager has outperformed for you or not, it is claimed, is irrelevant to how you should expect them to perform in the future. However, a key idea in statistics, called Bayesian thinking, suggests the opposite: that you should use any new information you get about something to update your thinking on it.\nIn this work, I therefore used Bayesian thinking to understand the advice that asset owners should get. It turns out that this advice makes common sense, particularly when paired with an understanding of whether the asset manager has some longer-term cyclicality in their performance.\nHere’s that video that I mentioned:"
  },
  {
    "objectID": "posts/wordle/index.html",
    "href": "posts/wordle/index.html",
    "title": "Winning at Wordle",
    "section": "",
    "text": "Let’s start by getting the ~500 most commonly-occurring five-letter words (that I downloaded as a csv file from the internet).\n\nsuppressPackageStartupMessages(library(tidyverse))\n\nwords &lt;- \n  read_csv(\n    file = \"five-letters.csv\", \n    col_names = FALSE\n    ) |&gt; \n  rename(\"word\" = X1) |&gt; \n  mutate(word = str_to_lower(word)) |&gt; \n  mutate(\n    l1 = str_sub(string = word, start = 1, end = 1),\n    l2 = str_sub(string = word, start = 2, end = 2),\n    l3 = str_sub(string = word, start = 3, end = 3),\n    l4 = str_sub(string = word, start = 4, end = 4),\n    l5 = str_sub(string = word, start = 5, end = 5)\n  )\n\nwords\n\n\n  \n\n\n\nFor reference, I’ll also chart the popularity of each letter by their order in these five-letter words.\n\nwords_long &lt;- words |&gt; \n  pivot_longer(\n    cols = -word, \n    names_to = \"measure\", \n    values_to = \"values\"\n    ) |&gt; \n  mutate(\n    position = as.integer(\n      str_sub(string = measure, start = 2)\n      )\n    ) |&gt; \n  select(values, position)\n\nwords_long |&gt; \n  count(values, position) |&gt; \n  mutate(\n    position = case_match(\n      position,\n      1 ~ \"1st\",\n      2 ~ \"2nd\",\n      3 ~ \"3rd\",\n      4 ~ \"4th\",\n      5 ~ \"5th\"\n      )\n    ) |&gt; \n  ggplot(\n    aes(\n      x = values, \n      y = n, \n      fill = values %in% c(\"a\", \"e\", \"r\", \"s\", \"t\")\n      )\n    ) + \n  geom_col() + \n  scale_y_continuous(\n    limits = c(0, NA), \n    minor_breaks = NULL, \n    expand = expansion(mult = 0, add = 1)\n    ) + \n  scale_fill_manual(values = c(\"#edd9c0\", \"#63431c\")) +\n  facet_wrap(~position, nrow = 1) + \n  theme_minimal() + \n  labs(\n    title = \"Frequency of letter by word order\",\n    subtitle = \"Emphasis on the letters a, e, r, s and t\\n\",\n    x = NULL,\n    y = NULL\n  ) +\n  theme(\n    legend.position = \"none\",\n    plot.title.position = \"plot\"\n    )\n\n\n\n\n\n\n\n\nAs you can see from the emphasis, some of these letters appear a lot more than others, and especially at the start and end of the word."
  },
  {
    "objectID": "posts/wordle/index.html#footnotes",
    "href": "posts/wordle/index.html#footnotes",
    "title": "Winning at Wordle",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThese ‘best’ guesses might not be perfect, as my assumptions above and the approach in general could probably be improved, perhaps with Operational Research techniques. That said, I suspect that ‘stare’ and the next guesses are decent approximations to the ideal solution.↩︎"
  },
  {
    "objectID": "posts/brexit/index.html",
    "href": "posts/brexit/index.html",
    "title": "Brexit vote analysis",
    "section": "",
    "text": "You can scroll down for an interactive chart of each constituency, but the following chart shows the main detail.\n\n\n&lt;/&gt;\nlibrary(dplyr)\nlibrary(forcats)\nlibrary(ggiraph)\nlibrary(glue)\nlibrary(ggplot2)\nlibrary(ggtext)\nlibrary(parlitools)\nlibrary(scales)\n\nmap_details &lt;- west_hex_map\nsf::st_crs(map_details) = 4326\n\ndata_brexit &lt;- leave_votes_west |&gt;  \n  rename(`Leave Vote` = figure_to_use) |&gt; \n  mutate(\n    `Party of MP` = as_factor(party_2016), \n    `Party of MP` = \n      recode(\n        `Party of MP`,\n        `Scottish National Party` = \"SNP\", \n        `Liberal Democrat` = \"LibDem\"\n        ),\n    `Party of MP` = fct_lump(\n      `Party of MP`,\n      n = 5, \n      other_level = \"Other\"\n      )\n    ) |&gt; \n  left_join(\n    map_details,\n    by = c(\"ons_const_id\" = \"gss_code\")\n    ) |&gt; \n  mutate(\n    constituency = if_else(\n      is.na(constituency_name.x), \n      constituency_name.y, \n      constituency_name.x\n      ),\n    vote_status = case_when(\n      (`Leave Vote` &gt;= 0) & (`Leave Vote` &lt;= 0.4) ~ \"Remain\",\n      (`Leave Vote` &gt; 0.4) & (`Leave Vote` &lt;= 0.6) ~ \"Close Call\",\n      (`Leave Vote` &gt; 0.6) & (`Leave Vote` &lt;= 1) ~ \"Leave\",\n      TRUE ~ \"Error\"\n      ),\n    vote_status = as_factor(vote_status),\n    vote_status = fct_relevel(vote_status, sort)\n    ) |&gt; \n  select(constituency, `Leave Vote`, `Party of MP`, ons_const_id, vote_status, geometry)\n\nhtml_text &lt;- glue(\"&lt;span&gt;Showing constituencies with &lt;span style='color:#0087DC;'&gt;Conservative&lt;/span&gt;, &lt;span style='color:#DC241F;'&gt;Labour&lt;/span&gt;, &lt;span style='color:#FFFF00;'&gt;SNP&lt;/span&gt;, &lt;span style='color:#FDBB30;'&gt;LibDem&lt;/span&gt; and &lt;span style='color:#AFAFAFAF;'&gt;Other&lt;/span&gt; MPs&lt;/span&gt;&lt;br/&gt;\")\n\ndata_brexit |&gt; \n  ggplot() + \n  geom_sf(\n    aes(\n      group = constituency,\n      geometry = geometry,\n      fill = `Party of MP`\n      ),\n    size = 0.1\n    ) + \n  scale_fill_manual(\n    values = c(\n      Conservative = \"#0087DC\",\n      Labour = \"#DC241F\",\n      SNP = \"#FFFF00\",\n      LibDem = \"#FDBB30\",\n      Other = \"grey80\"\n      )\n    ) + \n  facet_grid(~vote_status, margins = TRUE, drop = TRUE) +\n  theme_void() + \n  labs(\n    title = \"Leave voters seem to have a bigger split in party allegiance\",\n    subtitle = html_text\n  ) + \n  theme(\n    plot.title.position = \"plot\",\n    plot.subtitle = element_markdown(),\n    legend.position = \"none\",\n    plot.background = element_rect(\n      fill = \"grey90\", \n      colour = \"grey90\", \n      linewidth = 1\n      ),\n    plot.margin = margin(0.5, 0.5, 0.5, 0.5, \"cm\")\n    )\n\n\n\n\n\n\n\n\n\nBasically, outside of Scotland, there seems to be a bigger split in Leaver constituencies than in their Remainer counterparts.\nTo get the details for each constituency, hover over the relevant spot in the chart below.\n\n\n&lt;/&gt;\ngg &lt;- data_brexit |&gt; \n  ggplot() + \n  geom_sf_interactive(\n    aes(\n      group = constituency,\n      geometry = geometry,\n      fill = `Leave Vote`,\n      colour = `Party of MP`,\n      tooltip = paste0(\n        constituency, \n        \"\\n MP: \",\n        `Party of MP`,\n        \"\\n Leave vote: \",\n        round(`Leave Vote` * 100, 0),\n        \"%\"\n        )\n    ),\n    size = 0.1\n  ) + \n  scale_fill_gradient_interactive(\n    low = \"white\", \n    high = \"#63666a\",\n    labels = percent_format(accuracy = 1)\n    ) +\n  scale_colour_manual_interactive(\n    values = c(\n      Conservative = \"#0087DC\",\n      Labour = \"#DC241F\",\n      SNP = \"#FFFF00\",\n      LibDem = \"#FDBB30\",\n      Other = \"grey80\"\n      )\n    ) + \n  theme_void() +\n  labs(\n    title = \"Leave vote and winning party, by constituency\", \n    subtitle = \"Hover over a point for the details\"\n  ) + \n  theme(\n    legend.position = \"right\",\n    legend.text = element_text(size = 6, hjust = 0),\n    legend.title = element_text(size = 8)\n    )\n\ngirafe(ggobj = gg)"
  },
  {
    "objectID": "posts/portfolioRisk/index.html",
    "href": "posts/portfolioRisk/index.html",
    "title": "Projecting portfolio risk",
    "section": "",
    "text": "To do so, I’ll deliberately pick a minimal example and assume that our portfolio has the thirty-stock Dow-Jones Industrial Average (DJIA) as its index.\nI’ll show the results in a couple of paragraphs. Before that, let’s consider a little of the theory behind this analysis. Specifically, that the active variance of a portfolio relative to its index is: \\[\\omega^2 = X^T V X\\]\n, where:\nGiven this equation, I see that I need to begin the analysis by downloading the holdings of the index and the pricing data for the constituent stocks.\nlibrary(tidyquant)\nlibrary(tidyverse)\nlibrary(tsibble)\nlibrary(waldo)\n\n# weights_index &lt;- tq_index(\"DOW\")\n# write_rds(x = weights_index, file = \"weights_index.rds\")\n\n# stock_prices  &lt;- tq_get(\n#   x = weights_index |&gt; pull(symbol), \n#   get = \"stock.prices\", \n#   from = \"2022-01-01\")\n# write_rds(x = stock_prices, file = \"stock_prices.rds\", compress = \"xz\")"
  },
  {
    "objectID": "posts/portfolioRisk/index.html#footnotes",
    "href": "posts/portfolioRisk/index.html#footnotes",
    "title": "Projecting portfolio risk",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nFor the sake of simplicity, I only consider split-adjusted price returns rather than the equivalent total returns in this example↩︎\nThis might be a heroic assumption, as it implies an independence between the risks experienced in different months↩︎\nNote that the sum of these values will add to the total active variance, as this calculation is essentially vector multiplication.↩︎"
  },
  {
    "objectID": "posts/batting/index.html",
    "href": "posts/batting/index.html",
    "title": "Have batting averages improved over time?",
    "section": "",
    "text": "Batting averages seem to have changed over time, but not in the direction that you might expect.\nTypical averages have worsened over time, but only for top-order batsmen. Of course, that doesn’t necessarily mean that batting skill levels have declined, as other factors might also be involved.\nI’ll now explain how I arrived at this conclusion and the assumptions that I made along the way. The starting point, as ever, was data. Specifically, the wonderful data from the espnCricinfo stats engine.\n\nlibrary(rvest)\nlibrary(tidyverse)\n\nscrape_stats &lt;- function(value_count){\n  value_url &lt;- paste0(\n    \"https://stats.espncricinfo.com/ci/engine/stats/index.html?batting_positionmax1=\",\n    value_count,\n    \";batting_positionmin1=\",\n    value_count,\n    \";batting_positionval1=batting_position;class=1;filter=advanced;opposition=1;opposition=2;opposition=3;opposition=4;opposition=5;opposition=6;opposition=7;opposition=8;orderby=runs;qualmin1=20;qualval1=innings;size=200;template=results;type=batting\"\n    )\n  \n  read_html(value_url) |&gt; \n    rvest::html_table() |&gt; \n    _[[3]]\n}\n\ndata_scraped &lt;- map(\n  .x = 1:11, \n  .f = ~scrape_stats(value_count = .x)\n  ) |&gt; \n  list_rbind(names_to = \"order_batting\")\n\nwrite_rds(x = data_scraped, file = \"data_scraped.rds\")\n\nThat said, I only consider:\n\nPlayers with twenty innings or more\nScores for and against the ‘top sides’ (i.e. Australia, England, India, New Zealand, Pakistan, South Africa, Sri Lanka and the West Indies) at some point\n\nAfter a little more tidying, we get the following data on about 1,000 batsmen, sorted by batting order and (descending) average.\n\nsuppressPackageStartupMessages(library(tidyverse))\nlibrary(gganimate)\nlibrary(glue)\nlibrary(magick)\n\ndata_batsmen &lt;- read_rds(\"data_scraped.rds\") |&gt; \n  mutate(\n    Name = word(Player, start = 1L, end = -2L),\n    fullCountry = word(Player, -1),\n    Country = str_sub(fullCountry, 2,-2),\n    Start = as.integer(str_sub(Span, 1, 4)),\n    Decade = 10*trunc(Start/10),\n    Name = str_replace_all(Name, \"'\", \" \") \n    ) |&gt; \n  filter(!(Country %in% c(\"BAN\", \"ZIM\"))) |&gt; \n  select(Name, Country, Decade, \"Average\" = Ave, \"Innings\" = Inns, \"Order\" = order_batting) |&gt; \n  arrange(Order, desc(Average))\n\ndata_batsmen\n\n\n  \n\n\n\n\nWe can then analyse the data by batting order, using the splendid gganimate.\n\ndata_batsmen |&gt; \n  ggplot(\n    aes(\n      x = Decade,\n      y = Average,\n      color = Country, \n      size = Innings\n      )\n    ) +\n  geom_point(alpha = 1) +\n  labs(\n    x = \"First decade of the batsman's career\",\n    y = \"\"\n    ) + \n  theme_minimal() +\n  ggtitle(\n    'Players who have ever batted at {closest_state} in the order',\n    subtitle = 'Average when batting at that position'\n    ) + \n  transition_states(\n    states = Order,\n    transition_length = 2,\n    state_length = 1\n    ) + \n  ease_aes('cubic-in-out') \n\n\n\n\n\n\n\n\n\nAlthough that looks cool, I find it hard to detect patterns in animations, and so switch to a static plot.\n\ndata_batsmen |&gt; \n  ggplot(\n    aes(\n      x = Order,\n      y = Average,\n      colour = Decade\n      )\n    ) +\n  geom_jitter() +\n  scale_x_continuous(labels = c(1, 3, 5, 7, 9, 11), breaks = c(1, 3, 5, 7, 9, 11)) +\n  scale_y_continuous(labels = c(0, 50, 100), breaks = c(0, 50, 100)) +\n  facet_wrap(~Decade) +\n  theme_minimal() +\n  labs(\n    title = 'Data is limited before the 1950s\\n',\n    subtitle = 'Batting average, when batting at that position, for a career that started in the given decade',\n    x = \"\\nBatting order\",\n    y = NULL\n    ) + \n  theme(\n    plot.title.position = \"plot\",\n    legend.position = \"none\",\n    axis.title.x = element_text(hjust = 1)\n  )\n\n\n\n\n\n\n\n\n\nGiven the paucity of data before the 1950s and in this decade, it makes sense to drop these decades from our analysis. If we do so and also add best-fit lines to the decade-by-decade charts above, we get the following.\n\ndata_batsmen |&gt; \n  filter(\n    between(Decade, 1950, 2010)\n  ) |&gt;\n  mutate(Decade = as_factor(Decade)) |&gt; \n  ggplot(\n    aes(\n      x = Order,\n      y = Average,\n      colour = Decade\n      )\n    ) +\n  geom_jitter() + \n  geom_smooth(se = FALSE) + \n  scale_colour_brewer(palette = \"Blues\", direction = -1) +\n  scale_x_continuous(labels = c(1, 3, 5, 7, 9, 11), breaks = c(1, 3, 5, 7, 9, 11)) +\n  scale_y_continuous(labels = c(0, 50, 100), breaks = c(0, 50, 100)) +\n  facet_wrap(~Decade) +\n  theme_minimal() +\n  labs(\n    title = 'Typical averages by batting order follow a similar shape over the decades\\n',\n    subtitle = 'Batting average, when batting at that position, for a career that started in the given decade',\n    x = \"\\nBatting order\",\n    y = NULL\n    ) + \n  theme(\n    plot.title.position = \"plot\",\n    legend.position = \"none\",\n    axis.title.x = element_text(hjust = 1)\n  )\n\n\n\n\n\n\n\n\n\nTo get a better sense of the trends, let’s now just consider these best-fit lines as one chart, where darker lines represent earlier starting decades of a career.\n\ndata_batsmen |&gt; \n  filter(\n    between(Decade, 1950, 2010)\n  ) |&gt; \n  mutate(Decade = as_factor(Decade)) |&gt; \n  ggplot(\n    aes(\n      x = Order,\n      y = Average,\n      colour = Decade,\n      group = Decade\n      )\n    ) +\n  geom_smooth(se = FALSE) + \n  scale_colour_brewer(palette = \"Blues\", direction = -1) +\n  scale_x_continuous(labels = 1:11, breaks = 1:11, minor_breaks = NULL) +\n  scale_y_continuous(minor_breaks = NULL, limits = c(0, NA), labels = 20 * 0:2, breaks = 20 * 0:2) +\n  theme_minimal() +\n  labs(\n    title = 'Higher-order averages have typically declined since the 1950s\\n',\n    subtitle = 'Typical batting average, when batting at that position, for a career that started in the given decade',\n    colour = \"Decade start\",\n    x = \"\\nBatting order\",\n    y = NULL\n    ) + \n  theme(\n    plot.title.position = \"plot\",\n    axis.title.x = element_text(hjust = 1)\n  )\n\n\n\n\n\n\n\n\n\nSo, what does this chart show us?\nTo me, it shows that typical latter-order averages haven’t changed that much over the decades, whilst there’s a lot more variation by decade for the typical averages of higher-order batsmen. Furthermore, the lines with higher typical top-order averages all seem to be darker (and therefore earlier).\nTo get more specific, let’s split this top-order data into two eras: the 1950s to the 1970s; and the 1980s and beyond. I can then compare the typical top-order batting averages in these eras.\n\ndata_test &lt;- data_batsmen |&gt; \n  filter(\n    between(Decade, 1950, 2010),\n    Order &lt;= 5\n  ) |&gt; \n  mutate(is_1950s_to_1970s = Decade &lt;= 1970) |&gt; \n  select(Average, is_1950s_to_1970s) \n\nt.test(\n  data = data_test, \n  Average ~ is_1950s_to_1970s, \n  alternative = \"less\"\n  )\n\n\n    Welch Two Sample t-test\n\ndata:  Average by is_1950s_to_1970s\nt = -2.0788, df = 348.5, p-value = 0.01918\nalternative hypothesis: true difference in means between group FALSE and group TRUE is less than 0\n95 percent confidence interval:\n       -Inf -0.4100609\nsample estimates:\nmean in group FALSE  mean in group TRUE \n           39.55741            41.54190 \n\n\n\nOK, so that’s a lot of detail! But what does it show?\nEssentially, it says that the reduction in typical top-order batting averages since the 1950s to 1980s is statistically significant. (That is, beyond what we would usually expect from chance alone.)\nOf course, this reduction might not be solely due to lower inherent skill levels relative to the prevailing bowlers. Two possible reasons are that:\n\nThe game is now different to before, with DRS, helmets and masses of analysis\nSurvivor bias might be a factor. After all, we are only considering players with twenty or more innings, for and against the ‘top sides’; a point also complicated by the fact that there are now more test matches per year than in the past\n\nAs is often the way with cricket, so much is in the interpretation and debate. And that’s just another reason to love it!\n\n\n\n[Updated on March 25, 2023]"
  },
  {
    "objectID": "posts/prempredict/index.html",
    "href": "posts/prempredict/index.html",
    "title": "PremPredict",
    "section": "",
    "text": "After a good run of thirteen years, now feels like the right time to end our PremPredict competition.\nThanks to all of you who have shared in the fun over this time. I’m pleased to say that this included Les Penfold, Mike Finnis and Roger Gathercole.\nAs you’ll see below, though, this post and the Wall of Fame will remain here, always showing that Peter Finnis was left holding the crown!\n(Oh yeah – and always showing how some of the biggest football nerds remained winless.)\n\n\n\nPremPredict champions\n\n2007/08 – Robert Wye\n2008/09 – Les Penfold\n2009/10 – Beth Penfold\n2010/11 – George Quin and Miranda Stride\n2011/12 – Hannah Finnis\n2012/13 – Michael Cheeseman\n2013/14 – Danny Russell\n2014/15 – Mathew Saunders\n2015/16 – Roger Gathercole\n2016/17 – Luke Finnis\n2017/18 – George Quin\n2018/19 – Roger Gathercole\n2019/20 – Peter Finnis\n\n\nThanks again for all the fun!"
  }
]